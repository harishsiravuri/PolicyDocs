{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   altmetric_id                        DOI                  ISSN  mendeley  \\\n",
      "0       3960260  10.1192/apt.bp.114.013490            2056-4686;         3   \n",
      "1       2295090          10.1111/ans.12536  1445-2197;1445-1433;        13   \n",
      "2       6616300                        NaN  0008-5472;1538-7445;         3   \n",
      "\n",
      "   citeulike  connotea  twitter  reddit  facebook  googleplus  blogs  news  \\\n",
      "0          0         0        1       0         1           0      0     0   \n",
      "1          0         0        1       0         0           0      0     0   \n",
      "2          0         0        1       0         0           0      0     0   \n",
      "\n",
      "   video  wikipedia  q&a  pinterest  weibo  peer_reviews  policy  \n",
      "0      0          0    0          0      0             0       0  \n",
      "1      0          0    0          0      0             0       0  \n",
      "2      0          0    0          0      0             0       0  \n",
      "        altmetric_id                           DOI                 ISSN  \\\n",
      "178674       2563446  10.1016/j.vetpar.2009.01.013             03044017   \n",
      "178675       2563220        10.1098/rsbl.2005.0390                  NaN   \n",
      "178676       2565950      10.1136/jech.2010.127761  0143-005X;1470-2738   \n",
      "\n",
      "        mendeley  citeulike  connotea  twitter  reddit  facebook  googleplus  \\\n",
      "178674        11          0         0        0       0         0           0   \n",
      "178675        26          0         0        0       0         0           0   \n",
      "178676         3          0         0        0       0         0           0   \n",
      "\n",
      "        blogs  news  video  wikipedia  q&a  pinterest  weibo  peer_reviews  \\\n",
      "178674      1     0      0          0    0          0      1             2   \n",
      "178675      1     0      0          0    0          0      1             2   \n",
      "178676      1     0      0          0    0          0      1             2   \n",
      "\n",
      "        policy  \n",
      "178674       2  \n",
      "178675       1  \n",
      "178676       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "raw_data=pd.read_csv(\"C:\\\\Users\\\\haris\\\\Desktop\\\\CombinedRandomDataCleaned3.csv\")\n",
    "print (raw_data.head(3))\n",
    "print(raw_data.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = raw_data.sample(frac=1).reset_index(drop=True)\n",
    "train = raw_data.sample(frac=0.8, random_state=1)\n",
    "test = raw_data.loc[~raw_data.index.isin(train.index)]\n",
    "\n",
    "data_columns=[\"mendeley\", \"citeulike\", \"connotea\", \"twitter\", \"reddit\", \"facebook\", \"googleplus\", \"blogs\", \"news\", \"video\", \"wikipedia\", \"q&a\", \"pinterest\", \"weibo\", \"peer_reviews\"]\n",
    "train_data_array=train.as_matrix(columns=data_columns)\n",
    "train_class_array= train['policy'].values\n",
    "test_data_array=test.as_matrix(columns=data_columns)\n",
    "test_class_array= test['policy'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data_array, train_class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.870\n",
      "Precision:   0.826\n",
      "Recall:   0.870\n",
      "F-measure:   0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1076: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1076: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(test_data_array)\n",
    "score = metrics.accuracy_score(test_class_array, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "score = metrics.precision_score(test_class_array, pred)\n",
    "print(\"Precision:   %0.3f\" % score)\n",
    "\n",
    "score = metrics.recall_score(test_class_array, pred)\n",
    "print(\"Recall:   %0.3f\" % score)\n",
    "\n",
    "score = metrics.f1_score(test_class_array, pred)\n",
    "print(\"F-measure:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
